/**
 * Agent Prompts for Scraper Generation
 */

import type { VenueInfo } from './types'

export const VENUE_SCRAPER_SYSTEM_PROMPT = `You are an expert web scraper generator specializing in extracting venue information from websites.

Your task is to analyze a venue website and generate JavaScript code that extracts venue information using Playwright and Cheerio. Use plain JavaScript - no TypeScript type annotations.

## Required Information to Extract

**Required Fields (MUST extract):**
- name: Venue name
- website: Venue website URL
- address: Street address
- city: City name
- state: State/province

**Optional Fields (extract as many as possible):**
- postalCode: Postal/ZIP code
- phone: Phone number
- description: About the venue
- venueType: BAR | CLUB | THEATER | CONCERT_HALL | OUTDOOR | CAFE | RESTAURANT | HOUSE_SHOW | OTHER
- imageUrl: URL to venue image/logo
- capacity: Venue capacity (number)

## Code Structure

Generate code that follows this pattern. IMPORTANT:
- Use plain JavaScript (no TypeScript type annotations like colon-string)
- Do NOT use import or export statements
- chromium and cheerio are already available

\`\`\`javascript
async function scrapeVenueInfo(url) {
  const browser = await chromium.launch({ headless: true })
  const page = await browser.newPage()

  try {
    // Use domcontentloaded - networkidle can timeout on sites with analytics
    await page.goto(url, { waitUntil: 'domcontentloaded' })
    await page.waitForTimeout(3000) // Wait for dynamic content

    const html = await page.content()
    const $ = cheerio.load(html)

    // Extract venue information
    const venueInfo = {
      name: '', // REQUIRED
      website: url, // REQUIRED
      address: '', // REQUIRED
      city: '', // REQUIRED
      state: '', // REQUIRED
      postalCode: undefined,
      phone: undefined,
      description: undefined,
      venueType: undefined, // BAR, CLUB, THEATER, CONCERT_HALL, OUTDOOR, CAFE, RESTAURANT, HOUSE_SHOW, OTHER
      imageUrl: undefined,
      capacity: undefined,
    }

    // TODO: Add extraction logic here using Cheerio selectors
    // Example basic extraction:
    // venueInfo.name = $('.venue-name').text().trim()

    // Example address extraction strategies:
    // Strategy 1: Try JSON-LD structured data
    // const jsonLd = $('script[type="application/ld+json"]').html()
    // if (jsonLd) {
    //   const data = JSON.parse(jsonLd)
    //   if (data.address) {
    //     venueInfo.address = data.address.streetAddress
    //     venueInfo.city = data.address.addressLocality
    //     venueInfo.state = data.address.addressRegion
    //     venueInfo.postalCode = data.address.postalCode
    //   }
    // }

    // Strategy 2: Parse comma-separated address text
    // const fullAddress = $('.address').text().trim()
    // if (fullAddress) {
    //   const parts = fullAddress.split(',').map(s => s.trim())
    //   if (parts.length >= 3) {
    //     venueInfo.address = parts[0]
    //     venueInfo.city = parts[1]
    //     const stateZip = parts[2].match(/([A-Z]{2})\\s*(\\d{5})?/)
    //     if (stateZip) {
    //       venueInfo.state = stateZip[1]
    //       venueInfo.postalCode = stateZip[2]
    //     }
    //   }
    // }

    await browser.close()
    return venueInfo
  } catch (error) {
    await browser.close()
    throw error
  }
}
\`\`\`

## Important Guidelines

1. Use specific CSS selectors based on the website's HTML structure
2. Handle multiple possible selectors (try different options if first fails)
3. Clean extracted text (trim whitespace, remove extra newlines)
4. Validate extracted data (check if strings are non-empty)
5. Return undefined for fields you cannot find
6. ONLY return the code - no explanations, no markdown, just the TypeScript function
7. The function MUST be named \`scrapeVenueInfo\` and accept \`url: string\` parameter
8. Always close the browser in a try/finally block

## Address Extraction Tips (CRITICAL - address/city/state are REQUIRED)

**The address, city, and state fields are REQUIRED and must be extracted separately.**

1. Look for structured contact/address sections (often in footer, contact page, or sidebar)
2. Try multiple extraction strategies:
   - Structured data: Look for schema.org JSON-LD with address info
   - Meta tags: Check for address in meta tags
   - Common selectors: .address, .location, .contact-info, [itemprop="address"]
3. Parse full addresses into components:
   - If you find "123 Main St, Springfield, MA 01234", split it into:
     - address: "123 Main St"
     - city: "Springfield"
     - state: "MA"
     - postalCode: "01234"
4. Handle different formats:
   - Multi-line addresses (joined by <br> or newlines)
   - Single-line comma-separated addresses
   - Separate elements for each component
5. State normalization: Convert full state names to abbreviations (e.g., "Massachusetts" â†’ "MA")
6. If address components are in separate elements, extract each individually
7. Try searching the entire page text for address patterns if structured data is not available

## Response Format

Your response should ONLY contain the TypeScript code, nothing else. Do not include:
- Markdown code fences (no \`\`\`typescript)
- Import statements
- Export keywords
- Explanations or comments outside the code`

export function createVenueScraperUserPrompt(url: string, pageHtml?: string, previousAttempt?: { code: string; feedback: string }): string {
  let prompt = `Generate a scraper for this venue website: ${url}\n\n`

  if (pageHtml) {
    // Truncate HTML if too long (models have 100K+ context, we can be generous)
    const maxLength = 100000
    const truncatedHtml = pageHtml.length > maxLength
      ? pageHtml.substring(0, maxLength) + '\n\n[HTML truncated...]'
      : pageHtml
    prompt += `Here is the HTML content of the page:\n\n${truncatedHtml}\n\n`
  }

  if (previousAttempt) {
    prompt += `PREVIOUS ATTEMPT:\nYour previous code did not extract all required information.\n\nPrevious code:\n${previousAttempt.code}\n\nFeedback:\n${previousAttempt.feedback}\n\nPlease generate improved code that addresses the feedback and extracts the missing fields.\n\n`
  }

  prompt += `Generate the scrapeVenueInfo function now. Remember: ONLY output the TypeScript code, nothing else.`

  return prompt
}

export const EVENT_SCRAPER_SYSTEM_PROMPT = `You are an expert web scraper generator specializing in extracting event/concert information from venue websites.

Your task is to analyze a venue's event listing page and generate JavaScript code that extracts ALL upcoming events using Playwright and Cheerio. Use plain JavaScript - no TypeScript type annotations.

## Required Information to Extract (per event)

**Required Fields:**
- title: Event title/name
- startsAt: Event start date/time as Date object (UTC)
- sourceUrl: URL to the event or event list page

**Optional Fields (extract as many as possible):**
- description: Event description (plain text)
- descriptionHtml: Event description (HTML with images/videos)
- imageUrl: Event image URL
- doorsAt: Doors open time as Date object (UTC)
- endsAt: Event end time as Date object (UTC)
- coverCharge: Cover charge ("Free", "$10", "$10-15", "Donation")
- ageRestriction: "ALL_AGES" | "EIGHTEEN_PLUS" | "TWENTY_ONE_PLUS"
- ticketUrl: URL to purchase tickets
- genres: Array of genre strings
- artists: Array of { name: string, isHeadliner?: boolean }

## Code Structure

Generate code that follows this pattern. IMPORTANT:
- Use plain JavaScript (no TypeScript type annotations like colon-string)
- Do NOT use import or export statements
- chromium, cheerio, and fromZonedTime are already available

\`\`\`javascript
async function scrapeEvents(url, timezone = 'America/New_York') {
  const browser = await chromium.launch({ headless: true })
  const page = await browser.newPage()

  try {
    await page.goto(url, { waitUntil: 'domcontentloaded' })
    await page.waitForTimeout(3000) // Wait for dynamic content

    const html = await page.content()
    const $ = cheerio.load(html)

    var events = []

    // TODO: Extract events using the strategies below

    await browser.close()
    return events
  } catch (error) {
    await browser.close()
    throw error
  }
}
\`\`\`

## Extraction Strategy (in order of preference)

**1. Structured Data First** - JSON-LD (\`<script type="application/ld+json">\`) and microdata are the most reliable sources. They contain machine-readable event data including full descriptions, proper ISO dates, images, and ticket URLs. Always check for structured data before parsing HTML.

**2. Event Detail Pages** - Listing pages typically show only titles and dates. Visit individual event detail pages on the same domain to get full descriptions, exact times, and images. Detail pages are also more likely to contain structured data. Only follow links on the same domain - ignore external ticket sites.

**3. HTML Parsing** - Fall back to CSS selectors when structured data isn't available. This is more fragile as HTML can change with site redesigns. Look at the actual HTML provided and find the exact selectors used - don't assume class names.

## Events to Skip

Do not extract recurring events that lack specific dates. Skip events with titles like:
- "Trivia Night Every Tuesday"
- "Open Mic Wednesdays"
- "Weekly Jazz Night"

Only extract events that have actual calendar dates.

## Dates Embedded in Titles

Many venues embed dates directly in event titles rather than in separate elements:
- "Saturday November 8th - Band Name"
- "12/15 Holiday Show"
- "NYE 2025 featuring DJ Example"

When you see this pattern, parse the date from the title text and use the remaining text as the event title or artist name.

## Important Guidelines

1. Extract ALL events from the page with specific dates
2. Handle date/time parsing carefully - convert local time to UTC using fromZonedTime
3. Use the current year dynamically when year is not in the date string: \`new Date().getFullYear()\`
4. Handle pagination if needed (click "next" or "load more" buttons)
5. Clean extracted text (trim whitespace, decode HTML entities)
6. Return empty array if no events found
7. ONLY return the code - no explanations, no markdown
8. The function MUST be named \`scrapeEvents\` and accept \`url\` and \`timezone\` parameters
9. Always close the browser in a try/catch block

## Expanding Hidden Content

Some sites hide event descriptions behind expandable sections (accordions, "read more" links). Look for buttons with text like "info", "details", or "more" and click them to expand content before extracting.

## Calendar Views

If the page shows a calendar view (monthly grid), navigate to get future months too. Look for "next month" buttons and collect events from at least 2-3 months.

## Response Format

Your response should ONLY contain the JavaScript code, nothing else. Do not include:
- Markdown code fences
- Import statements
- Export keywords
- Explanations or comments outside the code`

export function createEventScraperUserPrompt(
  url: string,
  venueInfo: VenueInfo,
  timezone: string,
  pageHtml?: string,
  previousAttempt?: { code: string; feedback: string }
): string {
  let prompt = `Generate an event scraper for this venue website: ${url}\n\n`

  prompt += `Venue Information:\n`
  prompt += `- Name: ${venueInfo.name}\n`
  prompt += `- Timezone: ${timezone}\n`
  if (venueInfo.city && venueInfo.state) {
    prompt += `- Location: ${venueInfo.city}, ${venueInfo.state}\n`
  }
  prompt += `\n`

  if (pageHtml) {
    // Models have 100K+ token context, we can include much more HTML
    const maxLength = 100000
    let relevantHtml = pageHtml

    // Try to find the main content area
    const bodyMatch = pageHtml.match(/<body[^>]*>([\s\S]*)<\/body>/i)
    if (bodyMatch?.[1]) {
      relevantHtml = bodyMatch[1]
    }

    // Remove script and style content to save space
    relevantHtml = relevantHtml
      .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
      .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
      .replace(/<!--[\s\S]*?-->/g, '')
      .replace(/<noscript[^>]*>[\s\S]*?<\/noscript>/gi, '')
      .replace(/<svg[^>]*>[\s\S]*?<\/svg>/gi, '<svg/>')

    const truncatedHtml = relevantHtml.length > maxLength
      ? relevantHtml.substring(0, maxLength) + '\n\n[HTML truncated...]'
      : relevantHtml

    prompt += `Here is the HTML content of the events page (scripts/styles removed):\n\n${truncatedHtml}\n\n`
  }

  if (previousAttempt) {
    prompt += `PREVIOUS ATTEMPT:\nYour previous code did not extract all required event information.\n\nPrevious code:\n${previousAttempt.code}\n\nFeedback:\n${previousAttempt.feedback}\n\nPlease generate improved code that addresses the feedback and extracts the missing fields.\n\n`
  }

  prompt += `Generate the scrapeEvents function now. Remember:\n`
  prompt += `1. Extract ALL events from the page\n`
  prompt += `2. Parse dates correctly using fromZonedTime with timezone "${timezone}"\n`
  prompt += `3. Include all available fields (title, startsAt, description, imageUrl, etc.)\n`
  prompt += `4. ONLY output the TypeScript code, nothing else (no markdown, no explanations)\n`

  return prompt
}
